{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SQLA-Wrapper # SQLA-Wrapper is a wrapper for SQLAlchemy and Alembic that simplifies many aspects of its setup. It works with the newer 2.0 style query API introduced in SQLAlchemy 1.4 , and can be used with most web frameworks. Includes # A SQLAlchemy wrapper , that does all the SQLAlchemy setup and gives you: A scoped session extended with some useful active-record-like methods and pagination. A declarative base class. A helper for performant testing with a real database. from sqla_wrapper import SQLAlchemy db = SQLAlchemy ( \"sqlite:///db.sqlite\" , ** options ) # You can also use separated host, name, etc. # db = SQLAlchemy(user=\u2026, password=\u2026, host=\u2026, port=\u2026, name=\u2026) An Alembic wrapper that loads the config from your application instead of from separated alembic.ini and env.py files. from sqla_wrapper import Alembic , SQLAlchemy db = SQLAlchemy ( \u2026 ) alembic = Alembic ( db , \"db/migrations\" ) Installation # Install the package using pip . The SQLAlchemy and Alembic libraries will be installed as dependencies. pip install sqla-wrapper Resources # Source code (MIT Licensed) PyPI Change log","title":"Home"},{"location":"#sqla-wrapper","text":"SQLA-Wrapper is a wrapper for SQLAlchemy and Alembic that simplifies many aspects of its setup. It works with the newer 2.0 style query API introduced in SQLAlchemy 1.4 , and can be used with most web frameworks.","title":"SQLA-Wrapper"},{"location":"#includes","text":"A SQLAlchemy wrapper , that does all the SQLAlchemy setup and gives you: A scoped session extended with some useful active-record-like methods and pagination. A declarative base class. A helper for performant testing with a real database. from sqla_wrapper import SQLAlchemy db = SQLAlchemy ( \"sqlite:///db.sqlite\" , ** options ) # You can also use separated host, name, etc. # db = SQLAlchemy(user=\u2026, password=\u2026, host=\u2026, port=\u2026, name=\u2026) An Alembic wrapper that loads the config from your application instead of from separated alembic.ini and env.py files. from sqla_wrapper import Alembic , SQLAlchemy db = SQLAlchemy ( \u2026 ) alembic = Alembic ( db , \"db/migrations\" )","title":"Includes"},{"location":"#installation","text":"Install the package using pip . The SQLAlchemy and Alembic libraries will be installed as dependencies. pip install sqla-wrapper","title":"Installation"},{"location":"#resources","text":"Source code (MIT Licensed) PyPI Change log","title":"Resources"},{"location":"alembic-wrapper/","text":"Alembic wrapper # Alembic is great but it has a configuration problem. While you web application config is probably one or more python files and parameters loaded from environment variables and other sources, Alembic needs a static alembic.ini file. You are suppose to edit the almost-undocumented env.py file to customize it to your application. The Alembic wrapper class aims to simplify that set up so you can just use your application config, without any more config files to maintain. The actual database migrations are still handled by Alembic so you get exactly the same functionality. Set up # The Alembic() class require two arguments: A SQLAlchemy() instance and the path of the folder that will contain the migrations. from sqla_wrapper import Alembic , SQLAlchemy db = SQLAlchemy ( \u2026 ) alembic = Alembic ( db , \"db/migrations\" ) If the migrations folder doesn\u2019t exists, it will be created. CLI integrations # The only downside is that you can\u2019t use the alembic command-line tool anymore. Instead, all the usual Alembic command are be available as methods of the wrapper instance and you need to integrate them with your framework/application CLI. Is easier than it sounds, specially because the wrapper comes with one-line methods to extend Click (the CLI used by Flask by default) and pyCEO (arguably, the best CLI ever made). Integrating with Flask Click # from flask import Flask db = SQLAlchemy ( \u2026 ) alembic = Alembic ( \u2026 ) app = Flask ( __name__ ) app . cli . add_command ( alembic . get_flask_cli ( \"db\" )) Integrating with Click # import click db = SQLAlchemy ( \u2026 ) alembic = Alembic ( \u2026 ) @click . group () def cli (): pass cli . add_command ( alembic . get_click_cli ( \"db\" )) Integrating with pyCEO # from pyceo import Cli db = SQLAlchemy ( \u2026 ) alembic = Alembic ( \u2026 ) class Manage ( Cli ): db = alembic . get_pyceo_cli ( \"db\" ) cli = Manage ()","title":"Alembic wrapper"},{"location":"alembic-wrapper/#alembic-wrapper","text":"Alembic is great but it has a configuration problem. While you web application config is probably one or more python files and parameters loaded from environment variables and other sources, Alembic needs a static alembic.ini file. You are suppose to edit the almost-undocumented env.py file to customize it to your application. The Alembic wrapper class aims to simplify that set up so you can just use your application config, without any more config files to maintain. The actual database migrations are still handled by Alembic so you get exactly the same functionality.","title":"Alembic wrapper"},{"location":"alembic-wrapper/#set-up","text":"The Alembic() class require two arguments: A SQLAlchemy() instance and the path of the folder that will contain the migrations. from sqla_wrapper import Alembic , SQLAlchemy db = SQLAlchemy ( \u2026 ) alembic = Alembic ( db , \"db/migrations\" ) If the migrations folder doesn\u2019t exists, it will be created.","title":"Set up"},{"location":"alembic-wrapper/#cli-integrations","text":"The only downside is that you can\u2019t use the alembic command-line tool anymore. Instead, all the usual Alembic command are be available as methods of the wrapper instance and you need to integrate them with your framework/application CLI. Is easier than it sounds, specially because the wrapper comes with one-line methods to extend Click (the CLI used by Flask by default) and pyCEO (arguably, the best CLI ever made).","title":"CLI integrations"},{"location":"alembic-wrapper/#integrating-with-flask-click","text":"from flask import Flask db = SQLAlchemy ( \u2026 ) alembic = Alembic ( \u2026 ) app = Flask ( __name__ ) app . cli . add_command ( alembic . get_flask_cli ( \"db\" ))","title":"Integrating with Flask Click"},{"location":"alembic-wrapper/#integrating-with-click","text":"import click db = SQLAlchemy ( \u2026 ) alembic = Alembic ( \u2026 ) @click . group () def cli (): pass cli . add_command ( alembic . get_click_cli ( \"db\" ))","title":"Integrating with Click"},{"location":"alembic-wrapper/#integrating-with-pyceo","text":"from pyceo import Cli db = SQLAlchemy ( \u2026 ) alembic = Alembic ( \u2026 ) class Manage ( Cli ): db = alembic . get_pyceo_cli ( \"db\" ) cli = Manage ()","title":"Integrating with pyCEO"},{"location":"sqlalchemy-wrapper/","text":"SQLAlchemy wrapper class # The SQLAlchemy wrapper class is a light wrapper over regular SQLAlchemy, mainly to simplify the configuration. A SQLAlchemy instance gives you access to the following things: db.engine : An engine created with the future=True argument A scoped session db.s and a db.Session class to manually create one, both extended with some useful active-record-like methods. (See \u201cWorking with the session\u201d .) db.Model : A declarative base class db.create_all() and db.drop_all() methods to create and drop tables according to the models. db.test_transaction() : A helper for performant testing with a real database. (See \u201cTesting with a real database\u201d .) Set up # The only required argument is the connection URI. You can give it directly: from sqla_wrapper import SQLAlchemy db = SQLAlchemy ( \"postgresql://scott:tiger@localhost/test\" ) or as separated host, user, password, database name, etc. parameters, and SQLA-Wrapper will build the URI for you. from sqla_wrapper import SQLAlchemy db = SQLAlchemy ( dialect = \"postgresql\" , user = \"scott\" , password = \"tiger\" , host = \"localhost\" , name = \"test\" , ) After the setup, you will be interacting mostly directly with SQLAlchemy so I recommend reading the official SQLAlchemy tutorial if you haven\u2019t done it yet. Beyond the URI, the class also accepts an engine_options and a session_options dictionary to pass special options when creating the engine and/or the session. Declaring models # A SQLAlchemy instance provides a db.Model class to be used as a declarative base class for your models. from sqlalchemy import Column , Integer , String from .base import db class User ( db . Model ): id = Column ( Integer , primary_key = True ) name = Column ( String ( 128 )) The instance also includes all the functions and classes from sqlalchemy and sqlalchemy.orm so you don\u2019t need to import Column , Integer , String , etc. and do this instead: from .base import db class User ( db . Model ): id = db . Column ( db . Integer , primary_key = True ) name = db . Column ( db . String ( 128 )) To learn more about how to define database models, consult the SQLAlchemy ORM documentation .","title":"SQLAlchemy wrapper class"},{"location":"sqlalchemy-wrapper/#sqlalchemy-wrapper-class","text":"The SQLAlchemy wrapper class is a light wrapper over regular SQLAlchemy, mainly to simplify the configuration. A SQLAlchemy instance gives you access to the following things: db.engine : An engine created with the future=True argument A scoped session db.s and a db.Session class to manually create one, both extended with some useful active-record-like methods. (See \u201cWorking with the session\u201d .) db.Model : A declarative base class db.create_all() and db.drop_all() methods to create and drop tables according to the models. db.test_transaction() : A helper for performant testing with a real database. (See \u201cTesting with a real database\u201d .)","title":"SQLAlchemy wrapper class"},{"location":"sqlalchemy-wrapper/#set-up","text":"The only required argument is the connection URI. You can give it directly: from sqla_wrapper import SQLAlchemy db = SQLAlchemy ( \"postgresql://scott:tiger@localhost/test\" ) or as separated host, user, password, database name, etc. parameters, and SQLA-Wrapper will build the URI for you. from sqla_wrapper import SQLAlchemy db = SQLAlchemy ( dialect = \"postgresql\" , user = \"scott\" , password = \"tiger\" , host = \"localhost\" , name = \"test\" , ) After the setup, you will be interacting mostly directly with SQLAlchemy so I recommend reading the official SQLAlchemy tutorial if you haven\u2019t done it yet. Beyond the URI, the class also accepts an engine_options and a session_options dictionary to pass special options when creating the engine and/or the session.","title":"Set up"},{"location":"sqlalchemy-wrapper/#declaring-models","text":"A SQLAlchemy instance provides a db.Model class to be used as a declarative base class for your models. from sqlalchemy import Column , Integer , String from .base import db class User ( db . Model ): id = Column ( Integer , primary_key = True ) name = Column ( String ( 128 )) The instance also includes all the functions and classes from sqlalchemy and sqlalchemy.orm so you don\u2019t need to import Column , Integer , String , etc. and do this instead: from .base import db class User ( db . Model ): id = db . Column ( db . Integer , primary_key = True ) name = db . Column ( db . String ( 128 )) To learn more about how to define database models, consult the SQLAlchemy ORM documentation .","title":"Declaring models"},{"location":"testing-with-a-real-database/","text":"Testing with a real database # \u201cTesting with a real database, was not that supposed to be a no-no?\u201d - you might be thinking. Many tutorials have always reccomended mocking your database so your unit-tests are fast. More often than not, thiugh, that is bad advice. For databases like PostgreSQL or MySQLfor whatever short-term gains you might get, you lose in long-term maintainability. Mocking your database is not only a lot of overhead but, after a while, the mocks no longer reflect the actual code and what is happening on the real database server. We need each test to be isolated from others: you should never have to think about what other tests have put in the database. However, creating tables, loading fixtures, and dropping those tables for each test is too slow. The good news is, you don\u2019t need to do it for each test. You will not have to worry about database performance issues if you follow this setup. 1. Manually create an empty database for testing # First, you need to manually create a new (and empty) database for your tests to use. This could mean manually running a command like createdb myapp-tests or adding another database service in your development docker-compose.yml file. You should use the same type of database as the one used by your application. Otherwise, your tests could be affected by implementation details of the database engines, like the default order of null values, and not being able to test what would happen in production. 2. Prepare the database before running the test suite # The test database exists but is empty at this point, so before we run any test, we need to create all the tables and insert the minimal fixture data necessary to run the application. We must configure our tests to do this every time we run the tests, but only once. There is no need to run any migrations because we can create all the tables from the models definition. You can however \u201cstamp\u201d it with the latest revision if some test expects the alembic_version table to exists. pytest # With pytest this can be done with a session-scoped fixture: # conftest.py import pytest from myapp.models import db , alembic , load_fixture_data @pytest . fixture ( scope = \"session\" ) def dbsetup (): assert \"_test\" in db . url # better to be safe than sorry db . create_all () alembic . stamp () # optional load_fixture_data () # optional yield db . drop_all () unittest # With unitest , we do it with the setUpClass and tearDownClass class methods in a base class. Other test cases must inherit from this class to make it work. # base.py import unittest from myapp.models import db , alembic , load_fixture_data class DBTestCase ( unittest . TestCase ): @classmethod def setUpClass ( cls ): assert \"_test\" in db . url # better to be safe than sorry db . create_all () alembic . stamp () # optional load_fixture_data () # optional @classmethod def tearDownClass ( cls ): db . drop_all () 3. Run each test inside a transaction and rollback at the end # This part is the main trick, and sqla-wrapper includes a db.test_transaction() method that does it for you: trans = db . test_transaction () ... trans . close () By wrapping each test in a root transaction, we make sure that it will not alter the state of the database, even if we commit during the test since the transaction is rolled back on test teardown. There is only one caveat: if you want to allow tests to also use rollbacks within them, your database must support SAVEPOINT. Note test_transaction() internally follow this recipe: # 1. Start a transaction on a new connection connection = db . engine . connect () trans = connection . begin () # 2. Bind a new session to this connection session = db . Session ( bind = connection ) # and registers it as the new scoped session # 3. If your database supports it, start a savepoint to allow rollbacks within a test nested = connection . begin_nested () @event . listens_for ( session , \"after_transaction_end\" ) def end_savepoint ( session , transaction ): if not nested . is_active : nested = connection . begin_nested () # 4. Run the test # ... # 5. Finally, rollback any changes and close the connection. session . close () trans . rollback () connection . close () This recipe is what SQLAlchemy documentation recommends and even test in their own CI to ensure that it remains working as expected. pytest # With pytest , we can use a regular fixture and make it depend on the dbsetup() fixture we created before. Although this new fixture will run (automatically) before each test, the setup fixture will run only once, as we need to. # conftest.py import pytest from myapp.models import db , alembic , load_fixture_data @pytest . fixture ( scope = \"session\" ) def dbsetup (): # ... @pytest . fixture () def dbs ( dbsetup ): trans = db . test_transaction () # Or, if you need to rollback in your tests # = db.test_transaction(savepoint=True) yield trans . close () Then, we use that database session fixture for the tests that require interacting with the database. You can safely use the \u201cglobal\u201d scoped session, because it nows point to the test session. # test_something.py from myapp.models import db def test_something ( dbs ): db . s . execute ( some_stmt ) db . s . commit () ... unittest # With unittest we use the setUp() and tearDown() methods # base.py import unittest from myapp.models import db , alembic , load_fixture_data class DBTestCase ( unittest . TestCase ): @classmethod def setUpClass ( cls ): # ... @classmethod def tearDownClass ( cls ): # ... def setUp ( self ): self . _trans = db . test_transaction () # Or, if you need to rollback in your tests # = db.test_transaction(savepoint=True) def tearDown ( self ): self . _trans . close () # ... Then, we inherit from that class for the tests that require interacting with the database. # test_something.py from myapp.models import db from .base import DBTestCase class TestSomething ( DBTestCase ): def test_something ( self ): db . s . execute ( some_stmt ) db . s . commit () # ...","title":"Testing with a real database"},{"location":"testing-with-a-real-database/#testing-with-a-real-database","text":"\u201cTesting with a real database, was not that supposed to be a no-no?\u201d - you might be thinking. Many tutorials have always reccomended mocking your database so your unit-tests are fast. More often than not, thiugh, that is bad advice. For databases like PostgreSQL or MySQLfor whatever short-term gains you might get, you lose in long-term maintainability. Mocking your database is not only a lot of overhead but, after a while, the mocks no longer reflect the actual code and what is happening on the real database server. We need each test to be isolated from others: you should never have to think about what other tests have put in the database. However, creating tables, loading fixtures, and dropping those tables for each test is too slow. The good news is, you don\u2019t need to do it for each test. You will not have to worry about database performance issues if you follow this setup.","title":"Testing with a real database"},{"location":"testing-with-a-real-database/#1-manually-create-an-empty-database-for-testing","text":"First, you need to manually create a new (and empty) database for your tests to use. This could mean manually running a command like createdb myapp-tests or adding another database service in your development docker-compose.yml file. You should use the same type of database as the one used by your application. Otherwise, your tests could be affected by implementation details of the database engines, like the default order of null values, and not being able to test what would happen in production.","title":"1. Manually create an empty database for testing"},{"location":"testing-with-a-real-database/#2-prepare-the-database-before-running-the-test-suite","text":"The test database exists but is empty at this point, so before we run any test, we need to create all the tables and insert the minimal fixture data necessary to run the application. We must configure our tests to do this every time we run the tests, but only once. There is no need to run any migrations because we can create all the tables from the models definition. You can however \u201cstamp\u201d it with the latest revision if some test expects the alembic_version table to exists.","title":"2. Prepare the database before running the test suite"},{"location":"testing-with-a-real-database/#pytest","text":"With pytest this can be done with a session-scoped fixture: # conftest.py import pytest from myapp.models import db , alembic , load_fixture_data @pytest . fixture ( scope = \"session\" ) def dbsetup (): assert \"_test\" in db . url # better to be safe than sorry db . create_all () alembic . stamp () # optional load_fixture_data () # optional yield db . drop_all ()","title":"pytest"},{"location":"testing-with-a-real-database/#unittest","text":"With unitest , we do it with the setUpClass and tearDownClass class methods in a base class. Other test cases must inherit from this class to make it work. # base.py import unittest from myapp.models import db , alembic , load_fixture_data class DBTestCase ( unittest . TestCase ): @classmethod def setUpClass ( cls ): assert \"_test\" in db . url # better to be safe than sorry db . create_all () alembic . stamp () # optional load_fixture_data () # optional @classmethod def tearDownClass ( cls ): db . drop_all ()","title":"unittest"},{"location":"testing-with-a-real-database/#3-run-each-test-inside-a-transaction-and-rollback-at-the-end","text":"This part is the main trick, and sqla-wrapper includes a db.test_transaction() method that does it for you: trans = db . test_transaction () ... trans . close () By wrapping each test in a root transaction, we make sure that it will not alter the state of the database, even if we commit during the test since the transaction is rolled back on test teardown. There is only one caveat: if you want to allow tests to also use rollbacks within them, your database must support SAVEPOINT. Note test_transaction() internally follow this recipe: # 1. Start a transaction on a new connection connection = db . engine . connect () trans = connection . begin () # 2. Bind a new session to this connection session = db . Session ( bind = connection ) # and registers it as the new scoped session # 3. If your database supports it, start a savepoint to allow rollbacks within a test nested = connection . begin_nested () @event . listens_for ( session , \"after_transaction_end\" ) def end_savepoint ( session , transaction ): if not nested . is_active : nested = connection . begin_nested () # 4. Run the test # ... # 5. Finally, rollback any changes and close the connection. session . close () trans . rollback () connection . close () This recipe is what SQLAlchemy documentation recommends and even test in their own CI to ensure that it remains working as expected.","title":"3. Run each test inside a transaction and rollback at the end"},{"location":"testing-with-a-real-database/#pytest_1","text":"With pytest , we can use a regular fixture and make it depend on the dbsetup() fixture we created before. Although this new fixture will run (automatically) before each test, the setup fixture will run only once, as we need to. # conftest.py import pytest from myapp.models import db , alembic , load_fixture_data @pytest . fixture ( scope = \"session\" ) def dbsetup (): # ... @pytest . fixture () def dbs ( dbsetup ): trans = db . test_transaction () # Or, if you need to rollback in your tests # = db.test_transaction(savepoint=True) yield trans . close () Then, we use that database session fixture for the tests that require interacting with the database. You can safely use the \u201cglobal\u201d scoped session, because it nows point to the test session. # test_something.py from myapp.models import db def test_something ( dbs ): db . s . execute ( some_stmt ) db . s . commit () ...","title":"pytest"},{"location":"testing-with-a-real-database/#unittest_1","text":"With unittest we use the setUp() and tearDown() methods # base.py import unittest from myapp.models import db , alembic , load_fixture_data class DBTestCase ( unittest . TestCase ): @classmethod def setUpClass ( cls ): # ... @classmethod def tearDownClass ( cls ): # ... def setUp ( self ): self . _trans = db . test_transaction () # Or, if you need to rollback in your tests # = db.test_transaction(savepoint=True) def tearDown ( self ): self . _trans . close () # ... Then, we inherit from that class for the tests that require interacting with the database. # test_something.py from myapp.models import db from .base import DBTestCase class TestSomething ( DBTestCase ): def test_something ( self ): db . s . execute ( some_stmt ) db . s . commit () # ...","title":"unittest"},{"location":"working-with-the-session/","text":"Working with the session # The Session is the mean to communicate with the database. There are two main ways to use it: Use the scoped session db.s # The \u201cscoped_session\u201d is really a proxy to a session automatically scoped to the current thread. This allows having a global session, so the session can be shared without the need to pass it explicitly. A scoped session is the recommended way to work in a web application, however, you must remember to call db.s.remove() the session at the end of the request. Use your framework\u2019s \u201con request end\u201d hook, to do that. For example, in Flask: @app . teardown_request def remove_db_scoped_session ( error = None ): db . s . remove () The db.s.remove() method close the current session and dispose it. A new session will be created when db.s is called again. Instantiate db.Session # You can use a context manager: with db . Session () as dbs : # work with the session here When the session is created in this way, a database transaction is automatically initiated when required, and the dbs.flush() , dbs.commit() , and dbs.rollback() methods can be used as needed. The session is automatically closed and returned to the session pool when the context manager block ends. You can also create it without a context manager and close it manually: dbs = db . Session (): # work with the session here dbs . close () Instantiate db.Session is the recommended way to work when the session is not shared like in a command-line script. Extra methods # SQLAlchemy default Session has the method db.s.get(Model, pk) to query and return a record by its primary key. SQLA-wrapper extends it with a few other ActiveRecord-like methods: .all(Model, **attrs) # Returns all the object found with these attributes. The filtering is done with a simple .filter_by() so is limited to \u201cequality\u201d comparisons against the columns of the model. Also, there is no way to sort the results. If you need sorting or more complex filtering, you are better served using a db.select() . Examples: users = db . s . all ( User ) users = db . s . all ( User , deleted = False ) users = db . s . all ( User , account_id = 123 , deleted = False ) .create(Model, **attrs) # Creates a new object and adds it to the session. This is a shortcut for: obj = Model ( ** attrs ) db . s . add ( obj ) db . s . flush () Note that this does a db.s.flush() , so you must later call db.s.commit() to persist the new object, You must later call db.s.commit() to persist the new object. Examples: new_user = db . s . create ( User , email = 'foo@example.com' ) db . s . commit () .first(Model, **attrs) # Returns the first object found with these attributes or None if there isn\u2019t one. The filtering is done with a simple .filter_by() so is limited to \u201cequality\u201d comparisons against the columns of the model. Also, there is no way to sort the results. If you need sorting or more complex filtering, you are better served using a db.select() . Examples: user = db . s . first ( User ) user = db . s . first ( User , deleted = False ) .first_or_create(Model, **attrs) # Tries to find an object and if none exists, it tries to creates a new one first. Use this method when you expect the object to already exists but want to create it in case it doesn\u2019t. This does a db.s.flush() , so you must later call db.s.commit() to persist the new object (in case one has been created). Examples: user1 = db . s . first_or_create ( User , email = 'foo@example.com' ) user2 = db . s . first_or_create ( User , email = 'foo@example.com' ) user1 is user2 .create_or_first(Model, **attrs) # Tries to create a new object, and if it fails because already exists, return the first it founds. For this to work one or more of the attributes must be unique so it does fail, otherwise you will be creating a new different object. Use this method when you expect that the object does not exists but want to avoid an exception in case it does. This does a db.s.flush() , so you must later call db.s.commit() to persist the new object (in case one has been created). Examples: user1 = db . s . create_or_first ( User , email = 'foo@example.com' ) user2 = db . s . create_or_first ( User , email = 'foo@example.com' ) user1 is user2 .paginate(query, total, page, per_page, padding) # Returns a Paginator of the query results. Note that you must calculate the total number of unpaginated results first. Example: query = select ( User ) \\ . where ( User . deleted == None ) . order_by ( User . created_at ) total = db . s . scalar ( select ( func . count ( User . id )) . where ( User . deleted == None ) ) pag = db . s . paginate ( query , total = total , page = 1 , per_page = 20 ) As always, I recommend reading the official SQLAlchemy tutorial to learn more how to work with the session.","title":"Working with the session"},{"location":"working-with-the-session/#working-with-the-session","text":"The Session is the mean to communicate with the database. There are two main ways to use it:","title":"Working with the session"},{"location":"working-with-the-session/#use-the-scoped-session-dbs","text":"The \u201cscoped_session\u201d is really a proxy to a session automatically scoped to the current thread. This allows having a global session, so the session can be shared without the need to pass it explicitly. A scoped session is the recommended way to work in a web application, however, you must remember to call db.s.remove() the session at the end of the request. Use your framework\u2019s \u201con request end\u201d hook, to do that. For example, in Flask: @app . teardown_request def remove_db_scoped_session ( error = None ): db . s . remove () The db.s.remove() method close the current session and dispose it. A new session will be created when db.s is called again.","title":"Use the scoped session db.s"},{"location":"working-with-the-session/#instantiate-dbsession","text":"You can use a context manager: with db . Session () as dbs : # work with the session here When the session is created in this way, a database transaction is automatically initiated when required, and the dbs.flush() , dbs.commit() , and dbs.rollback() methods can be used as needed. The session is automatically closed and returned to the session pool when the context manager block ends. You can also create it without a context manager and close it manually: dbs = db . Session (): # work with the session here dbs . close () Instantiate db.Session is the recommended way to work when the session is not shared like in a command-line script.","title":"Instantiate db.Session"},{"location":"working-with-the-session/#extra-methods","text":"SQLAlchemy default Session has the method db.s.get(Model, pk) to query and return a record by its primary key. SQLA-wrapper extends it with a few other ActiveRecord-like methods:","title":"Extra methods"},{"location":"working-with-the-session/#allmodel-attrs","text":"Returns all the object found with these attributes. The filtering is done with a simple .filter_by() so is limited to \u201cequality\u201d comparisons against the columns of the model. Also, there is no way to sort the results. If you need sorting or more complex filtering, you are better served using a db.select() . Examples: users = db . s . all ( User ) users = db . s . all ( User , deleted = False ) users = db . s . all ( User , account_id = 123 , deleted = False )","title":".all(Model, **attrs)"},{"location":"working-with-the-session/#createmodel-attrs","text":"Creates a new object and adds it to the session. This is a shortcut for: obj = Model ( ** attrs ) db . s . add ( obj ) db . s . flush () Note that this does a db.s.flush() , so you must later call db.s.commit() to persist the new object, You must later call db.s.commit() to persist the new object. Examples: new_user = db . s . create ( User , email = 'foo@example.com' ) db . s . commit ()","title":".create(Model, **attrs)"},{"location":"working-with-the-session/#firstmodel-attrs","text":"Returns the first object found with these attributes or None if there isn\u2019t one. The filtering is done with a simple .filter_by() so is limited to \u201cequality\u201d comparisons against the columns of the model. Also, there is no way to sort the results. If you need sorting or more complex filtering, you are better served using a db.select() . Examples: user = db . s . first ( User ) user = db . s . first ( User , deleted = False )","title":".first(Model, **attrs)"},{"location":"working-with-the-session/#first_or_createmodel-attrs","text":"Tries to find an object and if none exists, it tries to creates a new one first. Use this method when you expect the object to already exists but want to create it in case it doesn\u2019t. This does a db.s.flush() , so you must later call db.s.commit() to persist the new object (in case one has been created). Examples: user1 = db . s . first_or_create ( User , email = 'foo@example.com' ) user2 = db . s . first_or_create ( User , email = 'foo@example.com' ) user1 is user2","title":".first_or_create(Model, **attrs)"},{"location":"working-with-the-session/#create_or_firstmodel-attrs","text":"Tries to create a new object, and if it fails because already exists, return the first it founds. For this to work one or more of the attributes must be unique so it does fail, otherwise you will be creating a new different object. Use this method when you expect that the object does not exists but want to avoid an exception in case it does. This does a db.s.flush() , so you must later call db.s.commit() to persist the new object (in case one has been created). Examples: user1 = db . s . create_or_first ( User , email = 'foo@example.com' ) user2 = db . s . create_or_first ( User , email = 'foo@example.com' ) user1 is user2","title":".create_or_first(Model, **attrs)"},{"location":"working-with-the-session/#paginatequery-total-page-per_page-padding","text":"Returns a Paginator of the query results. Note that you must calculate the total number of unpaginated results first. Example: query = select ( User ) \\ . where ( User . deleted == None ) . order_by ( User . created_at ) total = db . s . scalar ( select ( func . count ( User . id )) . where ( User . deleted == None ) ) pag = db . s . paginate ( query , total = total , page = 1 , per_page = 20 ) As always, I recommend reading the official SQLAlchemy tutorial to learn more how to work with the session.","title":".paginate(query, total, page, per_page, padding)"}]}