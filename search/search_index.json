{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SQLA-Wrapper # SQLA-Wrapper is a wrapper for SQLAlchemy and Alembic that simplifies many aspects of its setup. It works with the newer 2.0 style query API introduced in SQLAlchemy 1.4 , and can be used with most web frameworks. Includes # A SQLAlchemy wrapper , that does all the SQLAlchemy setup and gives you: A scoped session extended with some useful active-record-like methods and pagination. A declarative base class. A helper for performant testing with a real database. from sqla_wrapper import SQLAlchemy db = SQLAlchemy ( \"sqlite:///db.sqlite\" , ** options ) # You can also use separated host, name, etc. # db = SQLAlchemy(user=\u2026, password=\u2026, host=\u2026, port=\u2026, name=\u2026) An Alembic wrapper that loads the config from your application instead of from separated alembic.ini and env.py files. from sqla_wrapper import Alembic , SQLAlchemy db = SQLAlchemy ( \u2026 ) alembic = Alembic ( db , \"db/migrations\" ) Installation # Install the package using pip . The SQLAlchemy and Alembic libraries will be installed as dependencies. pip install sqla-wrapper Resources # Source code (MIT Licensed) PyPI Change log","title":"Home"},{"location":"#sqla-wrapper","text":"SQLA-Wrapper is a wrapper for SQLAlchemy and Alembic that simplifies many aspects of its setup. It works with the newer 2.0 style query API introduced in SQLAlchemy 1.4 , and can be used with most web frameworks.","title":"SQLA-Wrapper"},{"location":"#includes","text":"A SQLAlchemy wrapper , that does all the SQLAlchemy setup and gives you: A scoped session extended with some useful active-record-like methods and pagination. A declarative base class. A helper for performant testing with a real database. from sqla_wrapper import SQLAlchemy db = SQLAlchemy ( \"sqlite:///db.sqlite\" , ** options ) # You can also use separated host, name, etc. # db = SQLAlchemy(user=\u2026, password=\u2026, host=\u2026, port=\u2026, name=\u2026) An Alembic wrapper that loads the config from your application instead of from separated alembic.ini and env.py files. from sqla_wrapper import Alembic , SQLAlchemy db = SQLAlchemy ( \u2026 ) alembic = Alembic ( db , \"db/migrations\" )","title":"Includes"},{"location":"#installation","text":"Install the package using pip . The SQLAlchemy and Alembic libraries will be installed as dependencies. pip install sqla-wrapper","title":"Installation"},{"location":"#resources","text":"Source code (MIT Licensed) PyPI Change log","title":"Resources"},{"location":"alembic-wrapper/","text":"Alembic wrapper # Alembic is great but it has a configuration problem. While you web application config is probably one or more python files and parameters loaded from environment variables and other sources, Alembic needs a static alembic.ini file. You are suppose to edit the almost-undocumented env.py file to customize it to your application. The Alembic wrapper class aims to simplify that set up so you can just use your application config, without any more config files to maintain. The actual database migrations are still handled by Alembic so you get exactly the same functionality. Set up # The Alembic() class require two arguments: A SQLAlchemy() instance and the path of the folder that will contain the migrations. from sqla_wrapper import Alembic , SQLAlchemy db = SQLAlchemy ( \u2026 ) alembic = Alembic ( db , \"db/migrations\" ) If the migrations folder doesn\u2019t exists, it will be created. CLI integrations # The only downside is that you can\u2019t use the alembic command-line tool anymore. Instead, all the usual Alembic command are be available as methods of the wrapper instance and you need to integrate them with your framework/application CLI. Is easier than it sounds, specially because the wrapper comes with one-line methods to extend Click (the CLI used by Flask by default) and pyCEO (arguably, the best CLI ever made). Integrating with Flask Click # from flask import Flask db = SQLAlchemy ( \u2026 ) alembic = Alembic ( \u2026 ) app = Flask ( __name__ ) app . cli . add_command ( alembic . get_flask_cli ( \"db\" )) Integrating with Click # import click db = SQLAlchemy ( \u2026 ) alembic = Alembic ( \u2026 ) @click . group () def cli (): pass cli . add_command ( alembic . get_click_cli ( \"db\" )) Integrating with pyCEO # from pyceo import Cli db = SQLAlchemy ( \u2026 ) alembic = Alembic ( \u2026 ) class Manage ( Cli ): db = alembic . get_pyceo_cli ( \"db\" ) cli = Manage () API # For a more in-depth understanding of these methods and the extra options, you can read the documentation for the Alembic config . class sqla_wrapper. Alembic ( db , path=\u2019db/migrations\u2019 , **options ) revision ( self , message , * , empty=False , parent=\u2019head\u2019 ) Create a new revision. Auto-generate operations by comparing models and database. Arguments : message : Revision message. empty : Generate just an empty migration file, not the operations. parent : Parent revision of this new revision. upgrade ( self , target=\u2019head\u2019 , * , sql=False , **kwargs ) Run migrations to upgrade database. Arguments : target : Revision target or \u201cfrom:to\u201d range if sql=True . \u201chead\u201d by default. sql : Don\u2019t emit SQL to database, dump to standard output instead. **kwargs : Optional arguments. If these are passed, they are sent directly to the upgrade() functions within each revision file. To use, modify the script.py.mako template file so that the upgrade() functions can accept arguments. downgrade ( self , target=\u2019-1\u2019 , * , sql=False , **kwargs ) Run migrations to downgrade database. Arguments : target : Revision target as an integer relative to the current state (e.g.: \u201c-1\u201d), or as a \u201cfrom:to\u201d range if sql=True . \u201c-1\u201d by default. sql : Don\u2019t emit SQL to database, dump to standard output instead. **kwargs : Optional arguments. If these are passed, they are sent directly to the downgrade() functions within each revision file. To use, modify the script.py.mako template file so that the downgrade() functions can accept arguments. get_history ( self , * , start=None , end=None ) Get the list of revisions in chronological order. You can optionally specify the range of revisions to return. Arguments : start : From this revision (including it.) end : To this revision (including it.) history ( self , * , verbose=False , start=\u2019base\u2019 , end=\u2019heads\u2019 ) Print the list of revisions in chronological order. You can optionally specify the range of revisions to return. Arguments : verbose : If True , shows also the path and the docstring of each revision file. start : Optional starting revision (including it.) end : Optional end revision (including it.) stamp ( self , target=\u2019head\u2019 , * , sql=False , purge=False ) Set the given revision in the revision table. Don\u2019t run migrations. Arguments : target : The target revision; \u201chead\u201d by default. sql : Don\u2019t emit SQL to the database, dump to the standard output instead. purge : Delete all entries in the version table before stamping. get_current ( self ) Get the last revision applied. current ( self , verbose=False ) Print the latest revision(s) applied. Arguments : verbose : If True , shows also the path and the docstring of the revision file. get_head ( self ) Get the latest revision. head ( self , verbose=False ) Print the latest revision. Arguments : verbose : If True , shows also the path and the docstring of the revision file. init ( self , path ) Creates a new migration folder with a script.py.mako template file. It doesn\u2019t fail if the folder or file already exists. Arguments : path : Target folder. create_all ( self ) Create all the tables from the current models and stamp the latest revision without running any migration. rev_id ( self ) Generate a unique id for a revision. By default this uses alembic.util.rev_id . Override this method to change it. get_pyceo_cli ( self ) get_click_cli ( self , name=\u2019db\u2019 ) get_flask_cli ( self , name=\u2019db\u2019 )","title":"Alembic wrapper"},{"location":"alembic-wrapper/#alembic-wrapper","text":"Alembic is great but it has a configuration problem. While you web application config is probably one or more python files and parameters loaded from environment variables and other sources, Alembic needs a static alembic.ini file. You are suppose to edit the almost-undocumented env.py file to customize it to your application. The Alembic wrapper class aims to simplify that set up so you can just use your application config, without any more config files to maintain. The actual database migrations are still handled by Alembic so you get exactly the same functionality.","title":"Alembic wrapper"},{"location":"alembic-wrapper/#set-up","text":"The Alembic() class require two arguments: A SQLAlchemy() instance and the path of the folder that will contain the migrations. from sqla_wrapper import Alembic , SQLAlchemy db = SQLAlchemy ( \u2026 ) alembic = Alembic ( db , \"db/migrations\" ) If the migrations folder doesn\u2019t exists, it will be created.","title":"Set up"},{"location":"alembic-wrapper/#cli-integrations","text":"The only downside is that you can\u2019t use the alembic command-line tool anymore. Instead, all the usual Alembic command are be available as methods of the wrapper instance and you need to integrate them with your framework/application CLI. Is easier than it sounds, specially because the wrapper comes with one-line methods to extend Click (the CLI used by Flask by default) and pyCEO (arguably, the best CLI ever made).","title":"CLI integrations"},{"location":"alembic-wrapper/#integrating-with-flask-click","text":"from flask import Flask db = SQLAlchemy ( \u2026 ) alembic = Alembic ( \u2026 ) app = Flask ( __name__ ) app . cli . add_command ( alembic . get_flask_cli ( \"db\" ))","title":"Integrating with Flask Click"},{"location":"alembic-wrapper/#integrating-with-click","text":"import click db = SQLAlchemy ( \u2026 ) alembic = Alembic ( \u2026 ) @click . group () def cli (): pass cli . add_command ( alembic . get_click_cli ( \"db\" ))","title":"Integrating with Click"},{"location":"alembic-wrapper/#integrating-with-pyceo","text":"from pyceo import Cli db = SQLAlchemy ( \u2026 ) alembic = Alembic ( \u2026 ) class Manage ( Cli ): db = alembic . get_pyceo_cli ( \"db\" ) cli = Manage ()","title":"Integrating with pyCEO"},{"location":"alembic-wrapper/#api","text":"For a more in-depth understanding of these methods and the extra options, you can read the documentation for the Alembic config . class sqla_wrapper. Alembic ( db , path=\u2019db/migrations\u2019 , **options ) revision ( self , message , * , empty=False , parent=\u2019head\u2019 ) Create a new revision. Auto-generate operations by comparing models and database. Arguments : message : Revision message. empty : Generate just an empty migration file, not the operations. parent : Parent revision of this new revision. upgrade ( self , target=\u2019head\u2019 , * , sql=False , **kwargs ) Run migrations to upgrade database. Arguments : target : Revision target or \u201cfrom:to\u201d range if sql=True . \u201chead\u201d by default. sql : Don\u2019t emit SQL to database, dump to standard output instead. **kwargs : Optional arguments. If these are passed, they are sent directly to the upgrade() functions within each revision file. To use, modify the script.py.mako template file so that the upgrade() functions can accept arguments. downgrade ( self , target=\u2019-1\u2019 , * , sql=False , **kwargs ) Run migrations to downgrade database. Arguments : target : Revision target as an integer relative to the current state (e.g.: \u201c-1\u201d), or as a \u201cfrom:to\u201d range if sql=True . \u201c-1\u201d by default. sql : Don\u2019t emit SQL to database, dump to standard output instead. **kwargs : Optional arguments. If these are passed, they are sent directly to the downgrade() functions within each revision file. To use, modify the script.py.mako template file so that the downgrade() functions can accept arguments. get_history ( self , * , start=None , end=None ) Get the list of revisions in chronological order. You can optionally specify the range of revisions to return. Arguments : start : From this revision (including it.) end : To this revision (including it.) history ( self , * , verbose=False , start=\u2019base\u2019 , end=\u2019heads\u2019 ) Print the list of revisions in chronological order. You can optionally specify the range of revisions to return. Arguments : verbose : If True , shows also the path and the docstring of each revision file. start : Optional starting revision (including it.) end : Optional end revision (including it.) stamp ( self , target=\u2019head\u2019 , * , sql=False , purge=False ) Set the given revision in the revision table. Don\u2019t run migrations. Arguments : target : The target revision; \u201chead\u201d by default. sql : Don\u2019t emit SQL to the database, dump to the standard output instead. purge : Delete all entries in the version table before stamping. get_current ( self ) Get the last revision applied. current ( self , verbose=False ) Print the latest revision(s) applied. Arguments : verbose : If True , shows also the path and the docstring of the revision file. get_head ( self ) Get the latest revision. head ( self , verbose=False ) Print the latest revision. Arguments : verbose : If True , shows also the path and the docstring of the revision file. init ( self , path ) Creates a new migration folder with a script.py.mako template file. It doesn\u2019t fail if the folder or file already exists. Arguments : path : Target folder. create_all ( self ) Create all the tables from the current models and stamp the latest revision without running any migration. rev_id ( self ) Generate a unique id for a revision. By default this uses alembic.util.rev_id . Override this method to change it. get_pyceo_cli ( self ) get_click_cli ( self , name=\u2019db\u2019 ) get_flask_cli ( self , name=\u2019db\u2019 )","title":"API"},{"location":"api/","text":"API Reference # SQLAlchemy wrapper class # class sqla_wrapper. SQLAlchemy ( url=None , * , dialect=\u2019sqlite\u2019 , name=None , user=None , password=None , host=None , port=None , engine_options=None , session_options=None ) Create a SQLAlchemy connection This class creates an engine, a base class for your models, and a scoped session. The string form of the URL is dialect[+driver]://user:password@host/dbname[?key=value..] , where dialect is a database name such as mysql, postgresql, etc., and driver the name of a DBAPI, such as psycopg2, pyodbc, etc. Instead of the connection URL you can also specify dialect (plus optional driver), user, password, host, port, and database name as separate arguments. Please review the Database URLs section of the SQLAlchemy documentation, for general guidelines in composing URL strings. In particular, special characters, such as those often part of passwords, must be URL-encoded to be properly parsed. Example: db = SQLAlchemy ( database_uri ) # or SQLAlchemy(dialect=, name= [, user=] [, password=] [, host=] [, port=]) class Base ( db . Model ): pass class User ( Base ): tablename = \"users\" id = Column ( Integer , primary_key = True ) login = Column ( String ( 80 ), unique = True ) deleted = Column ( DateTime ) create_all ( self , **kwargs ) Creates all the tables of the models registered so far. Only tables that do not already exist are created. Existing tables are not modified. drop_all ( self , **kwargs ) Drop all the database tables. Note that this is a destructive operation; data stored in the database will be deleted when this method is called. test_transaction ( self , savepoint=False ) Session class # class sqla_wrapper. Session ( bind=None , autoflush=True , future=False , expire_on_commit=True , autocommit=False , twophase=False , binds=None , enable_baked_queries=True , info=None , query_cls=None ) SQLAlchemy default Session class has the method .get(Model, pk) to query and return a record by its primary key. This class extends the sqlalchemy.orm.Session class with some useful active-record-like methods and a pagination helper. all ( self , Model , **attrs ) Returns all the object found with these attributes. The filtering is done with a simple .filter_by() so is limited to \u201cequality\u201d comparisons against the columns of the model. Also, there is no way to sort the results. If you need sorting or more complex filtering, you are better served using a db.select() . Examples : users = db . s . all ( User ) users = db . s . all ( User , deleted = False ) users = db . s . all ( User , account_id = 123 , deleted = False ) create ( self , Model , **attrs ) Creates a new object and adds it to the session. This is a shortcut for: obj = Model ( ** attrs ) db . s . add ( obj ) db . s . flush () Note that this does a db.s.flush() , so you must later call db.s.commit() to persist the new object. Example : new_user = db . s . create ( User , email = ' foo@example.com ' ) db . s . commit () first ( self , Model , **attrs ) Returns the first object found with these attributes or None if there isn\u2019t one. The filtering is done with a simple .filter_by() so is limited to \u201cequality\u201d comparisons against the columns of the model. Also, there is no way to sort the results. If you need sorting or more complex filtering, you are better served using a db.select() . Examples : user = db . s . first ( User ) user = db . s . first ( User , deleted = False ) first_or_create ( self , Model , **attrs ) Tries to find an object and if none exists, it tries to create a new one first. Use this method when you expect the object to already exists but want to create it in case it doesn\u2019t. This does a db.s.flush() , so you must later call db.s.commit() to persist the new object (in case one has been created). Examples : user1 = db . s . first_or_create ( User , email = ' foo@example.com ' ) user2 = db . s . first_or_create ( User , email = ' foo@example.com ' ) user1 is user2 create_or_first ( self , Model , **attrs ) Tries to create a new object, and if it fails because already exists, return the first it founds. For this to work one or more of the attributes must be unique so it does fail, otherwise you will be creating a new different object. Use this method when you expect that the object does not exists but want to avoid an exception in case it does. This does a db.s.flush() , so you must later call db.s.commit() to persist the new object (in case one has been created). Examples : user1 = db . s . create_or_first ( User , email = ' foo@example.com ' ) user2 = db . s . create_or_first ( User , email = ' foo@example.com ' ) user1 is user2 paginate ( self , query , * , total , page=1 , per_page=20 , padding=0 ) Returns a Paginator of the query results. Note that you must calculate the total number of unpaginated results first. Arguments : query : A select() statement for all items. total : Total number of items. You must pre-calculate this value. page : Number of the current page (first page is 1 ) It can be a number, a string with a number, or the strings \u201cfirst\u201d or \u201clast\u201d. per_page : Max number of items to display on each page. padding : Number of elements of the previous and next page to show. For example, if per_page is 10 and padding is 2, every page will show 14 items, the first two from the previous page and the last two for the next one. This extra items will be repeated again on their own pages. Example : query = select ( User ) \\ . where ( User . deleted . is_ ( None )) \\ . order_by ( User . created_at ) total = db . s . scalar ( select ( func . count ( User . id )) . where ( User . deleted . is_ ( None )) ) pag = db . s . paginate ( query , total = total , page = 1 , per_page = 20 ) TestTransaction class # class sqla_wrapper. TestTransaction ( db , savepoint=False ) Helper for building sessions that rollback everyting at the end. See \u201cJoining a Session into an External Transaction\u201d in the SQLAlchemy documentation. close ( self ) Alembic wrapper class # class sqla_wrapper. Alembic ( db , path=\u2019db/migrations\u2019 , **options ) Provide an Alembic environment and migration API. For a more in-depth understanding of these methods and the extra options, you can read the documentation for the Alembic config . Arguments : db : A sqla_wrapper.SQLAlchemy instance. path : Path to the migrations folder. **options : Other alembic options revision ( self , message , * , empty=False , parent=\u2019head\u2019 ) Create a new revision. Auto-generate operations by comparing models and database. Arguments : message : Revision message. empty : Generate just an empty migration file, not the operations. parent : Parent revision of this new revision. upgrade ( self , target=\u2019head\u2019 , * , sql=False , **kwargs ) Run migrations to upgrade database. Arguments : target : Revision target or \u201cfrom:to\u201d range if sql=True . \u201chead\u201d by default. sql : Don\u2019t emit SQL to database, dump to standard output instead. **kwargs : Optional arguments. If these are passed, they are sent directly to the upgrade() functions within each revision file. To use, modify the script.py.mako template file so that the upgrade() functions can accept arguments. downgrade ( self , target=\u2019-1\u2019 , * , sql=False , **kwargs ) Run migrations to downgrade database. Arguments : target : Revision target as an integer relative to the current state (e.g.: \u201c-1\u201d), or as a \u201cfrom:to\u201d range if sql=True . \u201c-1\u201d by default. sql : Don\u2019t emit SQL to database, dump to standard output instead. **kwargs : Optional arguments. If these are passed, they are sent directly to the downgrade() functions within each revision file. To use, modify the script.py.mako template file so that the downgrade() functions can accept arguments. get_history ( self , * , start=None , end=None ) Get the list of revisions in chronological order. You can optionally specify the range of revisions to return. Arguments : start : From this revision (including it.) end : To this revision (including it.) history ( self , * , verbose=False , start=\u2019base\u2019 , end=\u2019heads\u2019 ) Print the list of revisions in chronological order. You can optionally specify the range of revisions to return. Arguments : verbose : If True , shows also the path and the docstring of each revision file. start : Optional starting revision (including it.) end : Optional end revision (including it.) stamp ( self , target=\u2019head\u2019 , * , sql=False , purge=False ) Set the given revision in the revision table. Don\u2019t run migrations. Arguments : target : The target revision; \u201chead\u201d by default. sql : Don\u2019t emit SQL to the database, dump to the standard output instead. purge : Delete all entries in the version table before stamping. get_current ( self ) Get the last revision applied. current ( self , verbose=False ) Print the latest revision(s) applied. Arguments : verbose : If True , shows also the path and the docstring of the revision file. get_head ( self ) Get the latest revision. head ( self , verbose=False ) Print the latest revision. Arguments : verbose : If True , shows also the path and the docstring of the revision file. init ( self , path ) Creates a new migration folder with a script.py.mako template file. It doesn\u2019t fail if the folder or file already exists. Arguments : path : Target folder. create_all ( self ) Create all the tables from the current models and stamp the latest revision without running any migration. rev_id ( self ) Generate a unique id for a revision. By default this uses alembic.util.rev_id . Override this method to change it. get_pyceo_cli ( self ) get_click_cli ( self , name=\u2019db\u2019 ) get_flask_cli ( self , name=\u2019db\u2019 ) Paginator class # class sqla_wrapper. Paginator ( query , * , page=1 , per_page=20 , total=None , padding=0 ) Helper class for paginate data. You can construct it from any iterable. Arguments : query : Items to paginate. page : Number of the current page (first page is 1 ) It can be a number, a string with a number, or the strings \u201cfirst\u201d or \u201clast\u201d. per_page : Max number of items to display on each page. total : Total number of items. If not provided, the length of the iterable will be used. padding : Number of elements of the previous and next page to show. For example, if per_page is 10 and padding is 2, every page will show 14 items, the first two from the previous page and the last two for the next one. This extra items will be repeated again on their own pages. num_pages The total number of pages. total_pages Alias to num_pages showing The number of items in the current page Could be less than per_page if we are in the last page, or more if padding > 0. is_paginated True if a more than one page exists. has_prev True if a previous page exists. has_next True if a next page exists. next_num Number of the next page. prev_num Number of the previous page. prev Returns a Paginator object for the previous page. next Returns a Paginator object for the next page. start_index 0-based index of the first element in the current page. end_index 0-based index of the last element in the current page. items Return the items to for the current page. pages Proxy to get_pages() get_range ( self , sep=\u2019 - \u2018 ) Return a string with the 1-based index range of items in the page (ignoring the padding). Useful for displaying \u201cShowing x - y items of z\u201d. Examples : p = Paginator ( range ( 100 ), per_page = 10 , page = 1 ) p . get_range () '1 - 10' p = Paginator ( range ( 100 ), per_page = 10 , page = 5 ) p . get_range () '41 - 50' get_pages ( self , showmax=12 ) Return a list of the page numbers in the pagination. The showmax parameter control how many numbers are shown at most. Depending of the page number and the showmax value, there are several possible scenarios, but the these rules are followed: The first, last and current pages are always returned. After those three, the remaining slots are filled around the current page, after the first page, and before the last page, in that order, in turns. Skipped page numbers are represented as None . We never skip just one page, so the final number of pages shown could be less than the value of showmax . Examples : [ ( 1 ), 2 , 3 , 4 , 5 , 6 , None , 10 , 11 , 12 , 13 ] [ 1 , 2 , None , 5 , 6 , 7 , ( 8 ), 9 , 10 , None , 13 , 14 , 15 ] [ 1 , 2 , ( 3 ), 4 , 5 ] This is one way how you could render such a pagination in the template: <p>Showing {{ pg.showing }} or {{ pg.total }} </p> <ol class=\"pg\"> {% - if pg.has_prev %} <li><a href=\" {{ url_for ( endpoint , page = pg.prev_num ) }} \" rel=\"me prev\">\u00ab</a></li> {% else %} <li class=\"disabled\"><span>\u00ab</span></li> {% - endif %} {% - for page in pg.pages %} {% if page %} {% if page != pg.page %} <li><a href=\" {{ url_for ( endpoint , page = page ) }} \" rel=\"me\"> {{ page }} </a></li> {% else %} <li class=\"current\"><span> {{ page }} </span></li> {% endif %} {% else %} <li><span class=ellipsis>\u2026</span></li> {% endif %} {% - endfor %} {% - if pg.has_next %} <li><a href=\" {{ url_for ( endpoint , page = pg.next_num ) }} \" rel=\"me next\">\u00bb</a></li> {% else %} <li class=\"disabled\"><span>\u00bb</span></li> {% - endif %} </ol>","title":"API Reference"},{"location":"api/#api-reference","text":"","title":"API Reference"},{"location":"api/#sqlalchemy-wrapper-class","text":"class sqla_wrapper. SQLAlchemy ( url=None , * , dialect=\u2019sqlite\u2019 , name=None , user=None , password=None , host=None , port=None , engine_options=None , session_options=None ) Create a SQLAlchemy connection This class creates an engine, a base class for your models, and a scoped session. The string form of the URL is dialect[+driver]://user:password@host/dbname[?key=value..] , where dialect is a database name such as mysql, postgresql, etc., and driver the name of a DBAPI, such as psycopg2, pyodbc, etc. Instead of the connection URL you can also specify dialect (plus optional driver), user, password, host, port, and database name as separate arguments. Please review the Database URLs section of the SQLAlchemy documentation, for general guidelines in composing URL strings. In particular, special characters, such as those often part of passwords, must be URL-encoded to be properly parsed. Example: db = SQLAlchemy ( database_uri ) # or SQLAlchemy(dialect=, name= [, user=] [, password=] [, host=] [, port=]) class Base ( db . Model ): pass class User ( Base ): tablename = \"users\" id = Column ( Integer , primary_key = True ) login = Column ( String ( 80 ), unique = True ) deleted = Column ( DateTime ) create_all ( self , **kwargs ) Creates all the tables of the models registered so far. Only tables that do not already exist are created. Existing tables are not modified. drop_all ( self , **kwargs ) Drop all the database tables. Note that this is a destructive operation; data stored in the database will be deleted when this method is called. test_transaction ( self , savepoint=False )","title":"SQLAlchemy wrapper class"},{"location":"api/#session-class","text":"class sqla_wrapper. Session ( bind=None , autoflush=True , future=False , expire_on_commit=True , autocommit=False , twophase=False , binds=None , enable_baked_queries=True , info=None , query_cls=None ) SQLAlchemy default Session class has the method .get(Model, pk) to query and return a record by its primary key. This class extends the sqlalchemy.orm.Session class with some useful active-record-like methods and a pagination helper. all ( self , Model , **attrs ) Returns all the object found with these attributes. The filtering is done with a simple .filter_by() so is limited to \u201cequality\u201d comparisons against the columns of the model. Also, there is no way to sort the results. If you need sorting or more complex filtering, you are better served using a db.select() . Examples : users = db . s . all ( User ) users = db . s . all ( User , deleted = False ) users = db . s . all ( User , account_id = 123 , deleted = False ) create ( self , Model , **attrs ) Creates a new object and adds it to the session. This is a shortcut for: obj = Model ( ** attrs ) db . s . add ( obj ) db . s . flush () Note that this does a db.s.flush() , so you must later call db.s.commit() to persist the new object. Example : new_user = db . s . create ( User , email = ' foo@example.com ' ) db . s . commit () first ( self , Model , **attrs ) Returns the first object found with these attributes or None if there isn\u2019t one. The filtering is done with a simple .filter_by() so is limited to \u201cequality\u201d comparisons against the columns of the model. Also, there is no way to sort the results. If you need sorting or more complex filtering, you are better served using a db.select() . Examples : user = db . s . first ( User ) user = db . s . first ( User , deleted = False ) first_or_create ( self , Model , **attrs ) Tries to find an object and if none exists, it tries to create a new one first. Use this method when you expect the object to already exists but want to create it in case it doesn\u2019t. This does a db.s.flush() , so you must later call db.s.commit() to persist the new object (in case one has been created). Examples : user1 = db . s . first_or_create ( User , email = ' foo@example.com ' ) user2 = db . s . first_or_create ( User , email = ' foo@example.com ' ) user1 is user2 create_or_first ( self , Model , **attrs ) Tries to create a new object, and if it fails because already exists, return the first it founds. For this to work one or more of the attributes must be unique so it does fail, otherwise you will be creating a new different object. Use this method when you expect that the object does not exists but want to avoid an exception in case it does. This does a db.s.flush() , so you must later call db.s.commit() to persist the new object (in case one has been created). Examples : user1 = db . s . create_or_first ( User , email = ' foo@example.com ' ) user2 = db . s . create_or_first ( User , email = ' foo@example.com ' ) user1 is user2 paginate ( self , query , * , total , page=1 , per_page=20 , padding=0 ) Returns a Paginator of the query results. Note that you must calculate the total number of unpaginated results first. Arguments : query : A select() statement for all items. total : Total number of items. You must pre-calculate this value. page : Number of the current page (first page is 1 ) It can be a number, a string with a number, or the strings \u201cfirst\u201d or \u201clast\u201d. per_page : Max number of items to display on each page. padding : Number of elements of the previous and next page to show. For example, if per_page is 10 and padding is 2, every page will show 14 items, the first two from the previous page and the last two for the next one. This extra items will be repeated again on their own pages. Example : query = select ( User ) \\ . where ( User . deleted . is_ ( None )) \\ . order_by ( User . created_at ) total = db . s . scalar ( select ( func . count ( User . id )) . where ( User . deleted . is_ ( None )) ) pag = db . s . paginate ( query , total = total , page = 1 , per_page = 20 )","title":"Session class"},{"location":"api/#testtransaction-class","text":"class sqla_wrapper. TestTransaction ( db , savepoint=False ) Helper for building sessions that rollback everyting at the end. See \u201cJoining a Session into an External Transaction\u201d in the SQLAlchemy documentation. close ( self )","title":"TestTransaction class"},{"location":"api/#alembic-wrapper-class","text":"class sqla_wrapper. Alembic ( db , path=\u2019db/migrations\u2019 , **options ) Provide an Alembic environment and migration API. For a more in-depth understanding of these methods and the extra options, you can read the documentation for the Alembic config . Arguments : db : A sqla_wrapper.SQLAlchemy instance. path : Path to the migrations folder. **options : Other alembic options revision ( self , message , * , empty=False , parent=\u2019head\u2019 ) Create a new revision. Auto-generate operations by comparing models and database. Arguments : message : Revision message. empty : Generate just an empty migration file, not the operations. parent : Parent revision of this new revision. upgrade ( self , target=\u2019head\u2019 , * , sql=False , **kwargs ) Run migrations to upgrade database. Arguments : target : Revision target or \u201cfrom:to\u201d range if sql=True . \u201chead\u201d by default. sql : Don\u2019t emit SQL to database, dump to standard output instead. **kwargs : Optional arguments. If these are passed, they are sent directly to the upgrade() functions within each revision file. To use, modify the script.py.mako template file so that the upgrade() functions can accept arguments. downgrade ( self , target=\u2019-1\u2019 , * , sql=False , **kwargs ) Run migrations to downgrade database. Arguments : target : Revision target as an integer relative to the current state (e.g.: \u201c-1\u201d), or as a \u201cfrom:to\u201d range if sql=True . \u201c-1\u201d by default. sql : Don\u2019t emit SQL to database, dump to standard output instead. **kwargs : Optional arguments. If these are passed, they are sent directly to the downgrade() functions within each revision file. To use, modify the script.py.mako template file so that the downgrade() functions can accept arguments. get_history ( self , * , start=None , end=None ) Get the list of revisions in chronological order. You can optionally specify the range of revisions to return. Arguments : start : From this revision (including it.) end : To this revision (including it.) history ( self , * , verbose=False , start=\u2019base\u2019 , end=\u2019heads\u2019 ) Print the list of revisions in chronological order. You can optionally specify the range of revisions to return. Arguments : verbose : If True , shows also the path and the docstring of each revision file. start : Optional starting revision (including it.) end : Optional end revision (including it.) stamp ( self , target=\u2019head\u2019 , * , sql=False , purge=False ) Set the given revision in the revision table. Don\u2019t run migrations. Arguments : target : The target revision; \u201chead\u201d by default. sql : Don\u2019t emit SQL to the database, dump to the standard output instead. purge : Delete all entries in the version table before stamping. get_current ( self ) Get the last revision applied. current ( self , verbose=False ) Print the latest revision(s) applied. Arguments : verbose : If True , shows also the path and the docstring of the revision file. get_head ( self ) Get the latest revision. head ( self , verbose=False ) Print the latest revision. Arguments : verbose : If True , shows also the path and the docstring of the revision file. init ( self , path ) Creates a new migration folder with a script.py.mako template file. It doesn\u2019t fail if the folder or file already exists. Arguments : path : Target folder. create_all ( self ) Create all the tables from the current models and stamp the latest revision without running any migration. rev_id ( self ) Generate a unique id for a revision. By default this uses alembic.util.rev_id . Override this method to change it. get_pyceo_cli ( self ) get_click_cli ( self , name=\u2019db\u2019 ) get_flask_cli ( self , name=\u2019db\u2019 )","title":"Alembic wrapper class"},{"location":"api/#paginator-class","text":"class sqla_wrapper. Paginator ( query , * , page=1 , per_page=20 , total=None , padding=0 ) Helper class for paginate data. You can construct it from any iterable. Arguments : query : Items to paginate. page : Number of the current page (first page is 1 ) It can be a number, a string with a number, or the strings \u201cfirst\u201d or \u201clast\u201d. per_page : Max number of items to display on each page. total : Total number of items. If not provided, the length of the iterable will be used. padding : Number of elements of the previous and next page to show. For example, if per_page is 10 and padding is 2, every page will show 14 items, the first two from the previous page and the last two for the next one. This extra items will be repeated again on their own pages. num_pages The total number of pages. total_pages Alias to num_pages showing The number of items in the current page Could be less than per_page if we are in the last page, or more if padding > 0. is_paginated True if a more than one page exists. has_prev True if a previous page exists. has_next True if a next page exists. next_num Number of the next page. prev_num Number of the previous page. prev Returns a Paginator object for the previous page. next Returns a Paginator object for the next page. start_index 0-based index of the first element in the current page. end_index 0-based index of the last element in the current page. items Return the items to for the current page. pages Proxy to get_pages() get_range ( self , sep=\u2019 - \u2018 ) Return a string with the 1-based index range of items in the page (ignoring the padding). Useful for displaying \u201cShowing x - y items of z\u201d. Examples : p = Paginator ( range ( 100 ), per_page = 10 , page = 1 ) p . get_range () '1 - 10' p = Paginator ( range ( 100 ), per_page = 10 , page = 5 ) p . get_range () '41 - 50' get_pages ( self , showmax=12 ) Return a list of the page numbers in the pagination. The showmax parameter control how many numbers are shown at most. Depending of the page number and the showmax value, there are several possible scenarios, but the these rules are followed: The first, last and current pages are always returned. After those three, the remaining slots are filled around the current page, after the first page, and before the last page, in that order, in turns. Skipped page numbers are represented as None . We never skip just one page, so the final number of pages shown could be less than the value of showmax . Examples : [ ( 1 ), 2 , 3 , 4 , 5 , 6 , None , 10 , 11 , 12 , 13 ] [ 1 , 2 , None , 5 , 6 , 7 , ( 8 ), 9 , 10 , None , 13 , 14 , 15 ] [ 1 , 2 , ( 3 ), 4 , 5 ] This is one way how you could render such a pagination in the template: <p>Showing {{ pg.showing }} or {{ pg.total }} </p> <ol class=\"pg\"> {% - if pg.has_prev %} <li><a href=\" {{ url_for ( endpoint , page = pg.prev_num ) }} \" rel=\"me prev\">\u00ab</a></li> {% else %} <li class=\"disabled\"><span>\u00ab</span></li> {% - endif %} {% - for page in pg.pages %} {% if page %} {% if page != pg.page %} <li><a href=\" {{ url_for ( endpoint , page = page ) }} \" rel=\"me\"> {{ page }} </a></li> {% else %} <li class=\"current\"><span> {{ page }} </span></li> {% endif %} {% else %} <li><span class=ellipsis>\u2026</span></li> {% endif %} {% - endfor %} {% - if pg.has_next %} <li><a href=\" {{ url_for ( endpoint , page = pg.next_num ) }} \" rel=\"me next\">\u00bb</a></li> {% else %} <li class=\"disabled\"><span>\u00bb</span></li> {% - endif %} </ol>","title":"Paginator class"},{"location":"sqlalchemy-wrapper/","text":"SQLAlchemy wrapper # The SQLAlchemy wrapper class is a light wrapper over regular SQLAlchemy, mainly to simplify the configuration. A SQLAlchemy instance gives you access to the following things: db.engine : An engine created with the future=True argument A scoped session db.s and a db.Session class to manually create one, both extended with some useful active-record-like methods. (See \u201cWorking with the session\u201d .) db.Model : A declarative base class db.create_all() and db.drop_all() methods to create and drop tables according to the models. db.test_transaction() : A helper for performant testing with a real database. (See \u201cTesting with a real database\u201d .) Set up # The only required argument is the connection URI. You can give it directly: from sqla_wrapper import SQLAlchemy db = SQLAlchemy ( \"postgresql://scott:tiger@localhost/test\" ) or as separated host, user, password, database name, etc. parameters, and SQLA-Wrapper will build the URI for you. from sqla_wrapper import SQLAlchemy db = SQLAlchemy ( dialect = \"postgresql\" , user = \"scott\" , password = \"tiger\" , host = \"localhost\" , name = \"test\" , ) After the setup, you will be interacting mostly directly with SQLAlchemy so I recommend reading the official SQLAlchemy tutorial if you haven\u2019t done it yet. Beyond the URI, the class also accepts an engine_options and a session_options dictionary to pass special options when creating the engine and/or the session. Declaring models # A SQLAlchemy instance provides a db.Model class to be used as a declarative base class for your models. from sqlalchemy import Column , Integer , String from .base import db class User ( db . Model ): id = Column ( Integer , primary_key = True ) name = Column ( String ( 128 )) The instance also includes all the functions and classes from sqlalchemy and sqlalchemy.orm so you don\u2019t need to import Column , Integer , String , etc. and do this instead: from .base import db class User ( db . Model ): id = db . Column ( db . Integer , primary_key = True ) name = db . Column ( db . String ( 128 )) To learn more about how to define database models, consult the SQLAlchemy ORM documentation . API # class sqla_wrapper. SQLAlchemy ( url=None , * , dialect=\u2019sqlite\u2019 , name=None , user=None , password=None , host=None , port=None , engine_options=None , session_options=None ) create_all ( self , **kwargs ) Creates all the tables of the models registered so far. Only tables that do not already exist are created. Existing tables are not modified. drop_all ( self , **kwargs ) Drop all the database tables. Note that this is a destructive operation; data stored in the database will be deleted when this method is called. test_transaction ( self , savepoint=False )","title":"SQLAlchemy wrapper"},{"location":"sqlalchemy-wrapper/#sqlalchemy-wrapper","text":"The SQLAlchemy wrapper class is a light wrapper over regular SQLAlchemy, mainly to simplify the configuration. A SQLAlchemy instance gives you access to the following things: db.engine : An engine created with the future=True argument A scoped session db.s and a db.Session class to manually create one, both extended with some useful active-record-like methods. (See \u201cWorking with the session\u201d .) db.Model : A declarative base class db.create_all() and db.drop_all() methods to create and drop tables according to the models. db.test_transaction() : A helper for performant testing with a real database. (See \u201cTesting with a real database\u201d .)","title":"SQLAlchemy wrapper"},{"location":"sqlalchemy-wrapper/#set-up","text":"The only required argument is the connection URI. You can give it directly: from sqla_wrapper import SQLAlchemy db = SQLAlchemy ( \"postgresql://scott:tiger@localhost/test\" ) or as separated host, user, password, database name, etc. parameters, and SQLA-Wrapper will build the URI for you. from sqla_wrapper import SQLAlchemy db = SQLAlchemy ( dialect = \"postgresql\" , user = \"scott\" , password = \"tiger\" , host = \"localhost\" , name = \"test\" , ) After the setup, you will be interacting mostly directly with SQLAlchemy so I recommend reading the official SQLAlchemy tutorial if you haven\u2019t done it yet. Beyond the URI, the class also accepts an engine_options and a session_options dictionary to pass special options when creating the engine and/or the session.","title":"Set up"},{"location":"sqlalchemy-wrapper/#declaring-models","text":"A SQLAlchemy instance provides a db.Model class to be used as a declarative base class for your models. from sqlalchemy import Column , Integer , String from .base import db class User ( db . Model ): id = Column ( Integer , primary_key = True ) name = Column ( String ( 128 )) The instance also includes all the functions and classes from sqlalchemy and sqlalchemy.orm so you don\u2019t need to import Column , Integer , String , etc. and do this instead: from .base import db class User ( db . Model ): id = db . Column ( db . Integer , primary_key = True ) name = db . Column ( db . String ( 128 )) To learn more about how to define database models, consult the SQLAlchemy ORM documentation .","title":"Declaring models"},{"location":"sqlalchemy-wrapper/#api","text":"class sqla_wrapper. SQLAlchemy ( url=None , * , dialect=\u2019sqlite\u2019 , name=None , user=None , password=None , host=None , port=None , engine_options=None , session_options=None ) create_all ( self , **kwargs ) Creates all the tables of the models registered so far. Only tables that do not already exist are created. Existing tables are not modified. drop_all ( self , **kwargs ) Drop all the database tables. Note that this is a destructive operation; data stored in the database will be deleted when this method is called. test_transaction ( self , savepoint=False )","title":"API"},{"location":"testing-with-a-real-database/","text":"Testing with a real database # \u201cTesting with a real database, was not that supposed to be a no-no?\u201d - you might be thinking. Many tutorials have always reccomended mocking your database so your unit-tests are fast. More often than not, thiugh, that is bad advice. For databases like PostgreSQL or MySQLfor whatever short-term gains you might get, you lose in long-term maintainability. Mocking your database is not only a lot of overhead but, after a while, the mocks no longer reflect the actual code and what is happening on the real database server. We need each test to be isolated from others: you should never have to think about what other tests have put in the database. However, creating tables, loading fixtures, and dropping those tables for each test is too slow. The good news is, you don\u2019t need to do it for each test. You will not have to worry about database performance issues if you follow this setup. 1. Manually create an empty database for testing # First, you need to manually create a new (and empty) database for your tests to use. This could mean manually running a command like createdb myapp-tests or adding another database service in your development docker-compose.yml file. You should use the same type of database as the one used by your application. Otherwise, your tests could be affected by implementation details of the database engines, like the default order of null values, and not being able to test what would happen in production. 2. Prepare the database before running the test suite # The test database exists but is empty at this point, so before we run any test, we need to create all the tables and insert the minimal fixture data necessary to run the application. We must configure our tests to do this every time we run the tests, but only once. There is no need to run any migrations because we can create all the tables from the models definition. You can however \u201cstamp\u201d it with the latest revision if some test expects the alembic_version table to exists. pytest # With pytest this can be done with a session-scoped fixture: # conftest.py import pytest from myapp.models import db , alembic , load_fixture_data @pytest . fixture ( scope = \"session\" ) def dbsetup (): assert \"_test\" in db . url # better to be safe than sorry db . create_all () alembic . stamp () # optional load_fixture_data () # optional yield db . drop_all () unittest # With unitest , we do it with the setUpClass and tearDownClass class methods in a base class. Other test cases must inherit from this class to make it work. # base.py import unittest from myapp.models import db , alembic , load_fixture_data class DBTestCase ( unittest . TestCase ): @classmethod def setUpClass ( cls ): assert \"_test\" in db . url # better to be safe than sorry db . create_all () alembic . stamp () # optional load_fixture_data () # optional @classmethod def tearDownClass ( cls ): db . drop_all () 3. Run each test inside a transaction and rollback at the end # This part is the main trick, and sqla-wrapper includes a db.test_transaction() method that does it for you: trans = db . test_transaction () ... trans . close () By wrapping each test in a root transaction, we make sure that it will not alter the state of the database, even if we commit during the test since the transaction is rolled back on test teardown. There is only one caveat: if you want to allow tests to also use rollbacks within them, your database must support SAVEPOINT. Note test_transaction() internally follow this recipe: # 1. Start a transaction on a new connection connection = db . engine . connect () trans = connection . begin () # 2. Bind a new session to this connection session = db . Session ( bind = connection ) # and registers it as the new scoped session # 3. If your database supports it, start a savepoint to allow rollbacks within a test nested = connection . begin_nested () @event . listens_for ( session , \"after_transaction_end\" ) def end_savepoint ( session , transaction ): if not nested . is_active : nested = connection . begin_nested () # 4. Run the test # ... # 5. Finally, rollback any changes and close the connection. session . close () trans . rollback () connection . close () This recipe is what SQLAlchemy documentation recommends and even test in their own CI to ensure that it remains working as expected. pytest # With pytest , we can use a regular fixture and make it depend on the dbsetup() fixture we created before. Although this new fixture will run (automatically) before each test, the setup fixture will run only once, as we need to. # conftest.py import pytest from myapp.models import db , alembic , load_fixture_data @pytest . fixture ( scope = \"session\" ) def dbsetup (): # ... @pytest . fixture () def dbs ( dbsetup ): trans = db . test_transaction () # Or, if you need to rollback in your tests # = db.test_transaction(savepoint=True) yield trans . close () Then, we use that database session fixture for the tests that require interacting with the database. You can safely use the \u201cglobal\u201d scoped session, because it nows point to the test session. # test_something.py from myapp.models import db def test_something ( dbs ): db . s . execute ( some_stmt ) db . s . commit () ... unittest # With unittest we use the setUp() and tearDown() methods # base.py import unittest from myapp.models import db , alembic , load_fixture_data class DBTestCase ( unittest . TestCase ): @classmethod def setUpClass ( cls ): # ... @classmethod def tearDownClass ( cls ): # ... def setUp ( self ): self . _trans = db . test_transaction () # Or, if you need to rollback in your tests # = db.test_transaction(savepoint=True) def tearDown ( self ): self . _trans . close () # ... Then, we inherit from that class for the tests that require interacting with the database. # test_something.py from myapp.models import db from .base import DBTestCase class TestSomething ( DBTestCase ): def test_something ( self ): db . s . execute ( some_stmt ) db . s . commit () # ... API # class sqla_wrapper. TestTransaction ( db , savepoint=False ) close ( self )","title":"Testing with a real database"},{"location":"testing-with-a-real-database/#testing-with-a-real-database","text":"\u201cTesting with a real database, was not that supposed to be a no-no?\u201d - you might be thinking. Many tutorials have always reccomended mocking your database so your unit-tests are fast. More often than not, thiugh, that is bad advice. For databases like PostgreSQL or MySQLfor whatever short-term gains you might get, you lose in long-term maintainability. Mocking your database is not only a lot of overhead but, after a while, the mocks no longer reflect the actual code and what is happening on the real database server. We need each test to be isolated from others: you should never have to think about what other tests have put in the database. However, creating tables, loading fixtures, and dropping those tables for each test is too slow. The good news is, you don\u2019t need to do it for each test. You will not have to worry about database performance issues if you follow this setup.","title":"Testing with a real database"},{"location":"testing-with-a-real-database/#1-manually-create-an-empty-database-for-testing","text":"First, you need to manually create a new (and empty) database for your tests to use. This could mean manually running a command like createdb myapp-tests or adding another database service in your development docker-compose.yml file. You should use the same type of database as the one used by your application. Otherwise, your tests could be affected by implementation details of the database engines, like the default order of null values, and not being able to test what would happen in production.","title":"1. Manually create an empty database for testing"},{"location":"testing-with-a-real-database/#2-prepare-the-database-before-running-the-test-suite","text":"The test database exists but is empty at this point, so before we run any test, we need to create all the tables and insert the minimal fixture data necessary to run the application. We must configure our tests to do this every time we run the tests, but only once. There is no need to run any migrations because we can create all the tables from the models definition. You can however \u201cstamp\u201d it with the latest revision if some test expects the alembic_version table to exists.","title":"2. Prepare the database before running the test suite"},{"location":"testing-with-a-real-database/#pytest","text":"With pytest this can be done with a session-scoped fixture: # conftest.py import pytest from myapp.models import db , alembic , load_fixture_data @pytest . fixture ( scope = \"session\" ) def dbsetup (): assert \"_test\" in db . url # better to be safe than sorry db . create_all () alembic . stamp () # optional load_fixture_data () # optional yield db . drop_all ()","title":"pytest"},{"location":"testing-with-a-real-database/#unittest","text":"With unitest , we do it with the setUpClass and tearDownClass class methods in a base class. Other test cases must inherit from this class to make it work. # base.py import unittest from myapp.models import db , alembic , load_fixture_data class DBTestCase ( unittest . TestCase ): @classmethod def setUpClass ( cls ): assert \"_test\" in db . url # better to be safe than sorry db . create_all () alembic . stamp () # optional load_fixture_data () # optional @classmethod def tearDownClass ( cls ): db . drop_all ()","title":"unittest"},{"location":"testing-with-a-real-database/#3-run-each-test-inside-a-transaction-and-rollback-at-the-end","text":"This part is the main trick, and sqla-wrapper includes a db.test_transaction() method that does it for you: trans = db . test_transaction () ... trans . close () By wrapping each test in a root transaction, we make sure that it will not alter the state of the database, even if we commit during the test since the transaction is rolled back on test teardown. There is only one caveat: if you want to allow tests to also use rollbacks within them, your database must support SAVEPOINT. Note test_transaction() internally follow this recipe: # 1. Start a transaction on a new connection connection = db . engine . connect () trans = connection . begin () # 2. Bind a new session to this connection session = db . Session ( bind = connection ) # and registers it as the new scoped session # 3. If your database supports it, start a savepoint to allow rollbacks within a test nested = connection . begin_nested () @event . listens_for ( session , \"after_transaction_end\" ) def end_savepoint ( session , transaction ): if not nested . is_active : nested = connection . begin_nested () # 4. Run the test # ... # 5. Finally, rollback any changes and close the connection. session . close () trans . rollback () connection . close () This recipe is what SQLAlchemy documentation recommends and even test in their own CI to ensure that it remains working as expected.","title":"3. Run each test inside a transaction and rollback at the end"},{"location":"testing-with-a-real-database/#pytest_1","text":"With pytest , we can use a regular fixture and make it depend on the dbsetup() fixture we created before. Although this new fixture will run (automatically) before each test, the setup fixture will run only once, as we need to. # conftest.py import pytest from myapp.models import db , alembic , load_fixture_data @pytest . fixture ( scope = \"session\" ) def dbsetup (): # ... @pytest . fixture () def dbs ( dbsetup ): trans = db . test_transaction () # Or, if you need to rollback in your tests # = db.test_transaction(savepoint=True) yield trans . close () Then, we use that database session fixture for the tests that require interacting with the database. You can safely use the \u201cglobal\u201d scoped session, because it nows point to the test session. # test_something.py from myapp.models import db def test_something ( dbs ): db . s . execute ( some_stmt ) db . s . commit () ...","title":"pytest"},{"location":"testing-with-a-real-database/#unittest_1","text":"With unittest we use the setUp() and tearDown() methods # base.py import unittest from myapp.models import db , alembic , load_fixture_data class DBTestCase ( unittest . TestCase ): @classmethod def setUpClass ( cls ): # ... @classmethod def tearDownClass ( cls ): # ... def setUp ( self ): self . _trans = db . test_transaction () # Or, if you need to rollback in your tests # = db.test_transaction(savepoint=True) def tearDown ( self ): self . _trans . close () # ... Then, we inherit from that class for the tests that require interacting with the database. # test_something.py from myapp.models import db from .base import DBTestCase class TestSomething ( DBTestCase ): def test_something ( self ): db . s . execute ( some_stmt ) db . s . commit () # ...","title":"unittest"},{"location":"testing-with-a-real-database/#api","text":"class sqla_wrapper. TestTransaction ( db , savepoint=False ) close ( self )","title":"API"},{"location":"working-with-the-session/","text":"Working with the session # The Session is the mean to communicate with the database. There are two main ways to use it: Use the scoped session db.s # The \u201cscoped_session\u201d is really a proxy to a session automatically scoped to the current thread. This allows having a global session, so the session can be shared without the need to pass it explicitly. A scoped session is the recommended way to work in a web application, however, you must remember to call db.s.remove() the session at the end of the request. Use your framework\u2019s \u201con request end\u201d hook, to do that. For example, in Flask: @app . teardown_request def remove_db_scoped_session ( error = None ): db . s . remove () The db.s.remove() method close the current session and dispose it. A new session will be created when db.s is called again. Instantiate db.Session # You can use a context manager: with db . Session () as dbs : # work with the session here When the session is created in this way, a database transaction is automatically initiated when required, and the dbs.flush() , dbs.commit() , and dbs.rollback() methods can be used as needed. The session is automatically closed and returned to the session pool when the context manager block ends. You can also create it without a context manager and close it manually: dbs = db . Session (): # work with the session here dbs . close () Instantiate db.Session is the recommended way to work when the session is not shared like in a command-line script. API # SQLAlchemy default Session class has the method .get(Model, pk) to query and return a record by its primary key. This class extends the sqlalchemy.orm.Session class with some useful active-record-like methods and a pagination helper. class sqla_wrapper. Session ( bind=None , autoflush=True , future=False , expire_on_commit=True , autocommit=False , twophase=False , binds=None , enable_baked_queries=True , info=None , query_cls=None ) all ( self , Model , **attrs ) Returns all the object found with these attributes. The filtering is done with a simple .filter_by() so is limited to \u201cequality\u201d comparisons against the columns of the model. Also, there is no way to sort the results. If you need sorting or more complex filtering, you are better served using a db.select() . Examples : users = db . s . all ( User ) users = db . s . all ( User , deleted = False ) users = db . s . all ( User , account_id = 123 , deleted = False ) create ( self , Model , **attrs ) Creates a new object and adds it to the session. This is a shortcut for: obj = Model ( ** attrs ) db . s . add ( obj ) db . s . flush () Note that this does a db.s.flush() , so you must later call db.s.commit() to persist the new object. Example : new_user = db . s . create ( User , email = ' foo@example.com ' ) db . s . commit () first ( self , Model , **attrs ) Returns the first object found with these attributes or None if there isn\u2019t one. The filtering is done with a simple .filter_by() so is limited to \u201cequality\u201d comparisons against the columns of the model. Also, there is no way to sort the results. If you need sorting or more complex filtering, you are better served using a db.select() . Examples : user = db . s . first ( User ) user = db . s . first ( User , deleted = False ) first_or_create ( self , Model , **attrs ) Tries to find an object and if none exists, it tries to create a new one first. Use this method when you expect the object to already exists but want to create it in case it doesn\u2019t. This does a db.s.flush() , so you must later call db.s.commit() to persist the new object (in case one has been created). Examples : user1 = db . s . first_or_create ( User , email = ' foo@example.com ' ) user2 = db . s . first_or_create ( User , email = ' foo@example.com ' ) user1 is user2 create_or_first ( self , Model , **attrs ) Tries to create a new object, and if it fails because already exists, return the first it founds. For this to work one or more of the attributes must be unique so it does fail, otherwise you will be creating a new different object. Use this method when you expect that the object does not exists but want to avoid an exception in case it does. This does a db.s.flush() , so you must later call db.s.commit() to persist the new object (in case one has been created). Examples : user1 = db . s . create_or_first ( User , email = ' foo@example.com ' ) user2 = db . s . create_or_first ( User , email = ' foo@example.com ' ) user1 is user2 paginate ( self , query , * , total , page=1 , per_page=20 , padding=0 ) Returns a Paginator of the query results. Note that you must calculate the total number of unpaginated results first. Arguments : query : A select() statement for all items. total : Total number of items. You must pre-calculate this value. page : Number of the current page (first page is 1 ) It can be a number, a string with a number, or the strings \u201cfirst\u201d or \u201clast\u201d. per_page : Max number of items to display on each page. padding : Number of elements of the previous and next page to show. For example, if per_page is 10 and padding is 2, every page will show 14 items, the first two from the previous page and the last two for the next one. This extra items will be repeated again on their own pages. Example : query = select ( User ) \\ . where ( User . deleted . is_ ( None )) \\ . order_by ( User . created_at ) total = db . s . scalar ( select ( func . count ( User . id )) . where ( User . deleted . is_ ( None )) ) pag = db . s . paginate ( query , total = total , page = 1 , per_page = 20 ) As always, I recommend reading the official SQLAlchemy tutorial to learn more how to work with the session.","title":"Working with the session"},{"location":"working-with-the-session/#working-with-the-session","text":"The Session is the mean to communicate with the database. There are two main ways to use it:","title":"Working with the session"},{"location":"working-with-the-session/#use-the-scoped-session-dbs","text":"The \u201cscoped_session\u201d is really a proxy to a session automatically scoped to the current thread. This allows having a global session, so the session can be shared without the need to pass it explicitly. A scoped session is the recommended way to work in a web application, however, you must remember to call db.s.remove() the session at the end of the request. Use your framework\u2019s \u201con request end\u201d hook, to do that. For example, in Flask: @app . teardown_request def remove_db_scoped_session ( error = None ): db . s . remove () The db.s.remove() method close the current session and dispose it. A new session will be created when db.s is called again.","title":"Use the scoped session db.s"},{"location":"working-with-the-session/#instantiate-dbsession","text":"You can use a context manager: with db . Session () as dbs : # work with the session here When the session is created in this way, a database transaction is automatically initiated when required, and the dbs.flush() , dbs.commit() , and dbs.rollback() methods can be used as needed. The session is automatically closed and returned to the session pool when the context manager block ends. You can also create it without a context manager and close it manually: dbs = db . Session (): # work with the session here dbs . close () Instantiate db.Session is the recommended way to work when the session is not shared like in a command-line script.","title":"Instantiate db.Session"},{"location":"working-with-the-session/#api","text":"SQLAlchemy default Session class has the method .get(Model, pk) to query and return a record by its primary key. This class extends the sqlalchemy.orm.Session class with some useful active-record-like methods and a pagination helper. class sqla_wrapper. Session ( bind=None , autoflush=True , future=False , expire_on_commit=True , autocommit=False , twophase=False , binds=None , enable_baked_queries=True , info=None , query_cls=None ) all ( self , Model , **attrs ) Returns all the object found with these attributes. The filtering is done with a simple .filter_by() so is limited to \u201cequality\u201d comparisons against the columns of the model. Also, there is no way to sort the results. If you need sorting or more complex filtering, you are better served using a db.select() . Examples : users = db . s . all ( User ) users = db . s . all ( User , deleted = False ) users = db . s . all ( User , account_id = 123 , deleted = False ) create ( self , Model , **attrs ) Creates a new object and adds it to the session. This is a shortcut for: obj = Model ( ** attrs ) db . s . add ( obj ) db . s . flush () Note that this does a db.s.flush() , so you must later call db.s.commit() to persist the new object. Example : new_user = db . s . create ( User , email = ' foo@example.com ' ) db . s . commit () first ( self , Model , **attrs ) Returns the first object found with these attributes or None if there isn\u2019t one. The filtering is done with a simple .filter_by() so is limited to \u201cequality\u201d comparisons against the columns of the model. Also, there is no way to sort the results. If you need sorting or more complex filtering, you are better served using a db.select() . Examples : user = db . s . first ( User ) user = db . s . first ( User , deleted = False ) first_or_create ( self , Model , **attrs ) Tries to find an object and if none exists, it tries to create a new one first. Use this method when you expect the object to already exists but want to create it in case it doesn\u2019t. This does a db.s.flush() , so you must later call db.s.commit() to persist the new object (in case one has been created). Examples : user1 = db . s . first_or_create ( User , email = ' foo@example.com ' ) user2 = db . s . first_or_create ( User , email = ' foo@example.com ' ) user1 is user2 create_or_first ( self , Model , **attrs ) Tries to create a new object, and if it fails because already exists, return the first it founds. For this to work one or more of the attributes must be unique so it does fail, otherwise you will be creating a new different object. Use this method when you expect that the object does not exists but want to avoid an exception in case it does. This does a db.s.flush() , so you must later call db.s.commit() to persist the new object (in case one has been created). Examples : user1 = db . s . create_or_first ( User , email = ' foo@example.com ' ) user2 = db . s . create_or_first ( User , email = ' foo@example.com ' ) user1 is user2 paginate ( self , query , * , total , page=1 , per_page=20 , padding=0 ) Returns a Paginator of the query results. Note that you must calculate the total number of unpaginated results first. Arguments : query : A select() statement for all items. total : Total number of items. You must pre-calculate this value. page : Number of the current page (first page is 1 ) It can be a number, a string with a number, or the strings \u201cfirst\u201d or \u201clast\u201d. per_page : Max number of items to display on each page. padding : Number of elements of the previous and next page to show. For example, if per_page is 10 and padding is 2, every page will show 14 items, the first two from the previous page and the last two for the next one. This extra items will be repeated again on their own pages. Example : query = select ( User ) \\ . where ( User . deleted . is_ ( None )) \\ . order_by ( User . created_at ) total = db . s . scalar ( select ( func . count ( User . id )) . where ( User . deleted . is_ ( None )) ) pag = db . s . paginate ( query , total = total , page = 1 , per_page = 20 ) As always, I recommend reading the official SQLAlchemy tutorial to learn more how to work with the session.","title":"API"}]}